% Initialize the transition matrix for the Markov chain
clc;clear;
P = [0.8,0.1,0.1;0.5,0.1,0.4;0.5,0.3,0.2];

%直接推Markov矩阵解
initial_state_probs = [1, 0, 0];
num_steps = 20;
state_matrix = zeros(num_steps, length(initial_state_probs));
% Set the initial state probabilities
state_matrix(1, :) = initial_state_probs;
% Iterate through the time steps
for t = 2:num_steps
    % Update the state probabilities using the transition matrix
    state_matrix(t, :) = state_matrix(t-1, :) * P;
end
disp(state_matrix);
%数值解
p=sym(P');
[x,y]=eig(p);
y=diag(y);  y=double(y);
ind=find(y==max(y));
p=x(:,ind)/sum()